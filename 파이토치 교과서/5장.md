# 파이토치 공부
## 5장
### 공부 책 : 딥러닝 파이토치 교과서 (길벗)

#### 합성곱 신경망 구조
1. 입력층
- 이미지 데이터는 높이, 너비, 채널 값을 가지는 3차원 데이터
- 채널은 그레이스케일이면 1, 컬러(RGB)면 3

2. 합성곱층 : 입력 데이터 특성 추출
- 특성 감지 위해 커널이나 필터 사용
- 스트라이드 : 필터를 적용하는 위치 간격
- 그레이스케일은 채널이 1이고 컬러는 채널이 3이므로 필터는 각각에 맞게 채널 수가 동일해야함 but 필터의 갯수는 하나임
- w: 가로, h : 높이, d : 채널, k : 필터 수, f : 필터 크기, s : 스트라이드, p : 패딩
- 출력 데이터 : w = (w1-f+2p)/(s+1), h = (h1-f+2p)/(s+1), d = k

3. 풀링층 : 특성 맵 차원 다운 샘플링 하여 연산량 감소, 주요 특성 벡터 추출
- 최대 풀링 : 대상 영역에서 최댓값 추출 (대부분 CNN에서 사용)
- 평균 풀링 : 대상 영역에서 평균을 반환

4. 완전연결층 : 3차원 벡터에서 1차원 벡터로 faltten

5. 출력층 : 소프트맥스 활성화 함수 사용, 가장 높은 확률 값 갖는 레이블 최종 값 선정

```python
#GPU 사용
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = Net()
model.to(device)

transform = transforms.Compose([transforms.ToTensor()]) # 이미지를 텐서화(0~1)
```
|구분|nn.xx|nn.functional.xx
|--|--|--
|형태|nn.Conv2d : 클래스 , nn.Module 클래스 상속받아 사용| nn.functional.conv2d : 함수, def function (input)으로 정의된 순수한 함수
|호출방법|하이퍼파라미터 전달 후 함수 호출 통해 데이터 전달| 하이퍼파라미터, 데이터 전달
|위치|nn.Sequential 내 위치| 할 수 없다.
|파라미터|파라미터 새로 정의 할 필요 없다| 가중치 수동 전달해야할 때 마다 자체 가중치 정의

```python
Varaiable(images.view(100,1,28,28)) #Autograd는 자동 미분을 수행 하는 기능으로 역전파 이용해 미분 값 자동 계산
# 합성곱네트워크 생성
class FashionCNN(nn.Module):
    def __init__(self):
        super(FashionCNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, padding = 1), #입력 채널 수가 1이면 흑백, 3이면 컬러
            # 출력 채널 수, 커널크기(필터), 출력크기 조정 위해 입력 데이터 주위 0 채움 (값 클 수록 출력 크기 커짐)
            nn.BatchNorm2d(32), #정규화 통해 분포를 가우시안 형태로 만듦
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2, stride = 2) #이미지 크기 축소 시키는 용도
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3,), #입력 채널 수가 1이면 흑백, 3이면 컬러
            # 출력 채널 수, 커널크기(필터)
            nn.BatchNorm2d(64), #정규화 통해 분포를 가우시안 형태로 만듦
            nn.ReLU(),
            nn.MaxPool2d(2) #이미지 크기 축소 시키는 용도
        )
        self.fc1 = nn.Linear(in_features = 64*6*6, out_features = 600)
        self.drop = nn.Dropdout2d(0.25)
        self.fc2 = nn.Linear(in_features = 600, out_features = 120)
        self.fc3 = nn.Linear(in_features = 120, out_features = 10)
        def forward(self, x):
            out = self.layer1(x)
            out = self.layer2(out)
            out = out.view(out.size(0),-1)
            out = self.fc1(out)
            out = self.drop(out)
            out = self.fc2(out)
            out = self.fc3(out)
            return out
learning_rate = 0.001
model = FashionCNN()
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)

num_epochs = 5
count = 0
loss_list = []
iteration_list = []
accuracy_list = []
predictions_list = []
labels_list = []

for epoch in range(num_epochs):
    for images, labels in train_lader:
        images, labels = images.to(device), labels.to(device)

        train = Variable(images.view(100,1,28,28))
        labels = Variable(labels)

        outputs = model(train)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        count +=1

        if not(count %50):
            total = 0
            correct = 0
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                labels_list.append(labels)
                test = Variable(images.view(100,1,28,28))
                outputs = model(test)
                predictions = torchmax(outputs,1)[1].to(device)
                predictions_list.append(predictions)
                correct += (predictions == labels).sum()
                total += len(labels)
            accuracy = correct *100 / total
            loss_list.append(loss.data)
            iteration_list.append(count)
            accuracy_list.append(accuracy)
        if not(count%500):
            print(count, loss.data, accuracy)
```

#### 전이학습
- 훈련된 모델의 가중치를 가져와 우리가 해결해야 할 문제에 맞게 보정해서 사용

1. 특성추출 기법
사전 훈련된 모델을 가져와 마지막 완전연결층 (이미지의 카테고리를 결정하는 부분)만 학습하고 나머지 계층들은 학습되지 않도록

- 합성공층 : 합성곱층, 풀링층으로 구성
- 데이터 분류기 (완전연결층) : 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류하는 부분

```python
transform = transforms.Compose(
    [
        transforms.Resize([256,256]), # 이미지 데이터 크기를 256x256으로 조정
        transforms.RandomResizedCrop(224), #이미지를 랜덤한 크기 및 비율로 자른 후 데이터 크기 조정
        transforms.RandomHorizontalFlip(), #이미지를 랜덤하게 수평으로 뒤집
        transforms.ToTensor(), #이미지 데이터 텐서화
    ])
torchvision.datasets.ImageFolder(path, transform = transform)
# 데이터 로더가 대상(경로)와 방법을 정의 받아 불러 들임
torch.utils.data.DataLoader(train, batch_size = 32, num_workers = 8, shuffle = True)
# 앞에서 imagefolder로 할당한 것을 파라미터 지정
iter(train).next() # 반복문을 사용하려면 필요
#iter로 반복자를 구한 후 next()에 전달해 차례대로 꺼냄

models.resnet18(pretrained = True) #resnet18에 있는 사전학습된 가중치를 사용
#resnet18에 있는 합성곱층을 사용하는 것임

def set_parameter(model, feature_extracting = True):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False # 역전파 중 파라미터 변화 계산할 필요 없으므로 학습을 하지 않도록 설정
resnet18.fc = nn.Linear(512,2) #클래스가 두개라는 의미로 완전연결층 추가

model = models.resnet18(pretained = True) #모델 객체 생성
for param in model.parameters(): #합성곱층 가중치 고정
    param.requires_grad = False
model.fc = torch.nn.Linear(512,2) #완전연결층 추가
for param in model.fc.parameters():
    param.requires_grad = True #완전연결층 학습
optimizer = torch.optim.Adam(model.fc.parameters()) 
cost = torch.nn.CrossEntropyLoss()#손실함수
print(model)

optimizer.zero_grad()
outputs = model(inputs) #순전파 학습
loss = criterion(outputs, labels) #손실함수 지정 값
_, preds = torch.max(outputs, 1) #텐서 배열의 최댓밗 index 반환 함수
loss.backward()
optimizer.step()

#테스트 셋에서는 autograd를 사용하지 않음
with torch.no_grad():
    outputs = model(inputs)
preds.eq(labels) #preds와 labels가 일치하는 검사

#예측 이미지 출력 전처리
def im_convert(tensor):
    image = tensor.clone().detach().numpy()
    # tensor.clone은 기존 텐서 내용 복사 텐서 생성
    # detach는 기존 텐서에서 기울기가 전파되지 않은 텐서 (계산 그래프에 상주 않음)
    image = image.transpose(1,2,0)
    image = image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))
    image = image.clip(0,1) #입력 값 특정 범위로 제한
    return image
```

2. 미세조정 기법
- 사전 훈련된 모델과 합성곱층, 데이터 분류기의 가중치 업데이트해 훈련
- 특성 추출은 목표 특성을 잘 추출했을 시 좋은 성능이지만 미세 조정은 가중치 업데이트 해 다시 추출(재학습, 일부 재학습)
- 과적합 주의 (파라미터 큰 변화 줄시)
    1. 데이터 셋 크고 훈련 모델과 유사성 클 경우 : 합성곱층 뒤부분과 데이터 분류기 학습
    2. 데이터 셋 크고 훈련 모델과 유사성 작을 경우 : 모델 전체 재학습
    3. 데이터 셋 작고 훈련 모델과 유사성 클 경우 : 데이터 분류기만 학습
    4. 데이터 셋 작고 훈련 모델과 유사성 작을 경우 : 합성곱층 일부분과 데이터 분류기 학습

#### 특성 맵 시각화
- 필터를 입력에 적응한 결과 (입력 특성 감지)
- from PIL import Image 사용

- log_softmax() : 신경망 말단의 결과값들 확률 개념으로 해석하기 위해 softmax 에 log 취한 값 -> softmax가 기울기 소멸에 취약하기에 로그 소프트 맥스 사용

```python
class LayerAcivations:
    features = []
    def __init__(self, model, layer_num):
        self.hook = model[layer_num].register_forward_hook(self.hook_fn)
    #hook 기능 사용해 각 계층 활성화 함수 및 기울기 값 확인
    def hook_fn(self, module, input, output):
        output = output
        self.features = output.detach().numpy()
    def remove(self):
        self.hook.remove()

img = cv.resize(img,(100,100), interpolation = cv2.INTER_LINEAR)
# 근사 함수를 적용해 새로운 픽셀 값 구하는 것이 보간법
img = ToTensor()(img).unsqueeze(0)
# unsqueeze 는 1차원 데이터 생성하겠다는 의미
# 이미지 데이터 텐서로 변환 후 변환 데이터 1차원 변경
```

#### 그래프 합성곱 네트워크
- 그래프 : 방향성이 있거나 없는 에지로 연결된 노드의 집합
    - 노드 : 원소
    - 에지 : 결합 방법 (노드를 연결한 선)

- 그래프 신경망 (GNN)
    1. 인접 행렬 - 네트워크 내 노드 n 개를 n x n 행렬로 표현 후 인접 행렬 내 값 관련성 여부를 채움
    2. 특성 행렬 - 단위행렬 적용 -> 특성 선택(각 노드가 갖는 값) -> 그래프 특성 추출
