# 파이토치 공부
## 8장
### 공부 책 : 딥러닝 파이토치 교과서 (길벗)

### 성능 최적화
1. 데이터 사용 성능 최적화
- 최대한 많은 데이터, 데이터를 생성
- 데이터 범위 조정
- 정규화, 규제화, 표준화

2. 알고리즘 튜닝
    1. train 성능이 test보다 너무 좋으면 과적합 의심 => 규제화 
    2. 둘 다 좋지 못하면 과소적합 의심 => 네트워크 구조 변경, 에포크 수 조정
    3. 가중치 초깃값은 작은 난수 or 오토인코더 비지도ㅗ 학습 이용해 사전 훈련 진행 후 지도 학습 진행
    4. 학습률 조정 (네트워크 계층 많을 시 높게, 계층 적을 시 작게)
    5. 활성화 함수 (주의해서 하기)
    6. 큰 에포크, 작은 배치 사용
    7. 옵티마이저는 확률적 경사하강법 많이 사용 => Adam or RMSProp 도 좋음

3. 앙상블 이용


#### 배치 정규화
1. 정규화 - 데이터 범위를 사용자 원하는 범위로 제한 == feature scaling ,주로 MinMaxScaler 사용
2. 규제화 - 모델 복잡도 줄임
    - 드롭아웃 : 일정 비율 뉴런만 사용하고 나머지 뉴런에 해당 가중치 업데이트 하지 않음       (nn.Dropout)
        - 훈련 시간 길어지지만 모델 성능 향상

    - 조기종료 : 매 에포크마다 검증 데이터 오차 측정하여 모델 종료 시점 제어
        - 언제 종료 시킬지 결정할 뿐 최고의 성능 보장 못함
    
    - 학습률 감소 - optim.lr_scheduler.RduceLR0nPlateau => 오차 변동 없을 시 학습률 factor배 감소
        - optim.lr_scheduler.RduceLR0nPlateau(self.optimizer, mode = 'min', patience = self.patience, fator = self.factor, min_lr = self.min_lr, verbose = True)
        - optimizer = 파라미터 갱신, mode = 언제 학습률 조정할 지 기준 , patience = 학습률 업데이트 하기 전 몇번 에포크 기다려야하는지
        factor = 학습률 얼마나 감소 시킬지, min_lr = 학습률 하한선, verbose = 조기 종료 시작과 끝

3. 표준화 - 평균 0, 표준편차 1 형태로 함, 주로 분포가 가우시안 분포 따를 때 유용

4. 배치 정규화 - 기울기 소멸 및 기울기 폭발 문제 해결     (nn.BatchNorm1d)
    - 기울기 소멸 및 폭발 원인은 내부 공변량 변화 때문 => 미니배치에 적용해 평균 0, 표준편차 1로 유지
    - 매 단계마다 활성화 함수 거치면서 데이터 셋 분포 일정 => 속도 향상
    - 배치 크기 작을 때 기존 값과 다른 방향으로 훈련 될 수 있음
    - 모델 더 복잡해져 비효율적
